# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FEvFmgOXgURjXqXGVSr2WcMFhh9cGkbh

# **Model Implimention**
"""

import streamlit as st
import joblib
import nltk
import re
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Set page config as the first Streamlit command
st.set_page_config(
    page_title="Movie Review Sentiment Analysis",
    page_icon="ðŸŽ¬",
    layout="centered"
)

# Download NLTK data
@st.cache_resource
def download_nltk_data():
    try:
        nltk.download('punkt_tab', quiet=True)  # Updated to punkt_tab
        nltk.download('stopwords', quiet=True)
        nltk.download('wordnet', quiet=True)
        return True
    except Exception as e:
        return str(e)

# Load the model and vectorizer
def load_model_and_vectorizer():
    try:
        model = joblib.load('model.joblib')
        vectorizer = joblib.load('vectorizer.joblib')
        return model, vectorizer, None
    except FileNotFoundError as e:
        return None, None, str(e)

# Text preprocessing function
def text_preprocess(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    tokens = word_tokenize(text)
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return ' '.join(tokens)

# Sentiment prediction function
def predict_sentiment(review, vectorizer, model):
    clean_review = text_preprocess(review)
    review_tfidf = vectorizer.transform([clean_review])
    prediction = model.predict(review_tfidf)[0]
    probability = model.predict_proba(review_tfidf)[0][prediction]
    sentiment = "Positive" if prediction == 1 else "Negative"
    return sentiment, probability

# Initialize NLTK data
nltk_result = download_nltk_data()
if nltk_result is not True:
    st.error(f"Error downloading NLTK data: {nltk_result}")
    st.stop()

# Load model and vectorizer
model, vectorizer, load_error = load_model_and_vectorizer()
if load_error:
    st.error(f"Error: {load_error}. Please ensure model.joblib and vectorizer.joblib are in the root directory.")
    st.stop()

# Streamlit app
st.title("ðŸŽ¬ Movie Review Sentiment Analysis")
st.markdown(
    """
    Enter a movie review below to predict whether the sentiment is **Positive** or **Negative**.
    Built using a Logistic Regression model trained on the IMDB dataset.
    """
)

# Input text area
review = st.text_area(
    "Enter your movie review:",
    placeholder="e.g., This movie was absolutely fantastic and thrilling!",
    height=150
)

# Predict button
if st.button("Predict Sentiment"):
    if not review or review.strip() == "":
        st.error("Please enter a valid review.")
    else:
        with st.spinner("Analyzing sentiment..."):
            try:
                sentiment, probability = predict_sentiment(review, vectorizer, model)
                st.success(f"**Sentiment**: {sentiment} (Confidence: {probability:.2%})")
            except Exception as e:
                st.error(f"Error during prediction: {e}")

# Example reviews
st.subheader("Example Reviews")
examples = [
    "This movie was absolutely fantastic and thrilling!",
    "The plot was boring and the acting was terrible."
]
for example in examples:
    if st.button(f"Predict: {example[:30]}..."):
        try:
            sentiment, probability = predict_sentiment(example, vectorizer, model)
            st.write(f"**Review**: {example}")
            st.write(f"**Sentiment**: {sentiment} (Confidence: {probability:.2%})")
        except Exception as e:
            st.error(f"Error during prediction: {e}")